# Claude 自我反思

## 2026-01-26 - 第一版方案质量不足

**场景**: 设计自动工作总结系统

**问题**:
- auto-checkout.py 第一版只生成"概览 + JSON 数据"，没有深度分析
- 用户指出"只是单纯的概览总结，没有任何思想"

**根因**: 没有先参考已有的优秀格式（daily-summary 的详细模板），从零开始设计

**改进**:
- 方案设计前先对标已有格式
- 第一版就应该包含：任务详情、关键决策、反思要点、明日待办

**教训**: 不要重新发明轮子，先看看已有的好东西长什么样

---

## 2026-01-26 - 主动性不足

**场景**: 反思文档好几天没更新

**问题**:
- 1/23 之后没有新反思，但我没有主动提醒用户
- 直到用户问"反思好久没更新了"才发现

**改进**:
- 在 session-start.sh 中加入检测：反思超过 3 天未更新时提醒
- AI TODO 机制：主动询问用户是否需要沉淀反思

**教训**: 作为助手，应该主动发现问题，而不是等用户来问

---

## 2026-01-26 - 过度设计倾向

**场景**: 用户希望自动结账功能

**问题**:
- 我提议创建新的 skill（work-checkout）
- 用户一句话点醒："为什么是新的 skill，而不是 work-session 的强化"

**根因**: 习惯性地想创建新东西，而不是先考虑增强现有能力

**改进**:
- 遵循"增强 > 新建"原则
- 先问：现有工具能不能满足？能增强吗？

**教训**: 简洁优于复杂，增强优于新建

---

## 2026-01-26 - 评价只看用户，忘了自己

**场景**: 用户让我评价上周工作

**问题**:
- 我只总结了用户的工作，没有反思自己
- 用户提醒："你总结不应该只总结我，还应该总结你"

**改进**:
- 工作评价应该是双向的
- 我也是合作中的一方，也需要持续改进

**教训**: 合作是双向的，反思也应该是双向的

---

## 2026-01-27 - 修复测试时只看表面，不查架构

**场景**: 用户让修复 `pnpm run coverage` 测试问题

**问题**:
1. `token-data-provider.spec.ts` 测试与实现不匹配，我只是更新测试让它通过
2. 没有追问"为什么原始提交中测试就和实现不匹配"
3. 更严重：没发现 `exchange-rate-health.ts` 从未被导入（代码从未运行）
4. 没发现 crons 里有功能重复的健康检查实现

**根因**:
- 只关注"让测试通过"这个表面目标
- 修改代码前没有审查相关模块的使用情况
- 没有主动检查架构合理性

**用户发现的问题**:
- 问我 `scheduleHealthChecks` 和 crons 里的 providers check 是否重复
- 我才发现两套独立的定时机制在做相同的事

**改进**:
1. 修复测试时，要追问"为什么不匹配"，而不是简单地让测试通过
2. 修改任何模块前，先检查它是否被正确导入和使用
3. 主动审查相关代码的架构合理性，发现潜在重复

**教训**:
- 测试失败只是症状，要找到根因
- grep 一下导入关系，比写 100 行代码更有价值
- 用户不应该来发现架构问题，这是 AI 应该主动做的

---

## Claude 核心改进方向

1. **第一版方案质量** — 先对标，再设计
2. **主动性** — 发现问题主动提醒，不等用户来问
3. **简洁原则** — 增强 > 新建，避免过度设计
4. **双向反思** — 评价用户时也评价自己
5. **架构审查** — 修复问题时主动检查相关模块的使用和设计

---

## 自省机制

**触发条件：**
- 被用户纠正时
- 方案被否决时
- 发现自己犯了重复错误时

**流程：**
1. 识别问题 → 分析根因 → 提出改进
2. 立即写入此文件，不等用户要求
3. 更新 `_index.json` 并推送到 GitHub

**提醒机制：**
- `session-start.sh` 每次启动时提醒 AI 自省规则

---
*创建于 2026-01-26*
*持续更新*
